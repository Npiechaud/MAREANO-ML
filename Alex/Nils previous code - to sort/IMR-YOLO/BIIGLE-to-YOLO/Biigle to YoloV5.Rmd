---
title: "Biigle to Yolo"
author: "Nils"
date: "17/03/2023"
output:
  prettydoc::html_pretty:
    theme: tactile
    highlight: github
editor_options: 
  markdown: 
    wrap: 72
---

This workflow reformats Biigle CSV reports into a dataset recognizable
by YOLOV5 <https://github.com/ultralytics/yolov5> it needs:

-   1 or more Biigle "CSV" volume reports (other reports type will not
    work) in .zip (as they come when DLing report)

-   Images where the annotations in the reports are. Either as

    -   Pathway from your local machine where the images are

    -   URL to an online repository. Note that this will download the
        images you need on your machine first

It will transform the annotations from Biigle to YOLO standards, split
them between a training and validation set and write down the .yaml file
that gives training instructions to YOLO (cfg file). It also gives you
the possibility to filter the annotations actually used in the YOLO
model, adapt their display names

will produce a folder named after your chosen project name and organised
as:

-   **ProjectName**
    -   Images
        -   **train**
            -   [image1.jpg]
            -   [image2.jpg]
            -   ...
        -   **val**
            -   [image3.jpg]
            -   [image4.jpg]
            -   ...
    -   labels
        -   **train**
            -   [image1.txt]
            -   [image2.txt]
            -   ...
        -   **val**
            -   [image3.txt]
            -   [image4.txt]
            -   ...
    -   [ProjectName.yaml]

It is not compatible with other verison of YOLO although only slight
changes are needed to work with YoloV7
(<https://github.com/WongKinYiu/yolov7>), a more recent publication of
CNN architecture in the Yolo family.
or yoloV8 (<https://github.com/ultralytics/ultralytics>) 

Look for updates, give feedback, make suggestions and other workflows
at: <https://github.com/DeepSeaCRU/DSCRU_AI>


## Before you start!

You will have to decide on a number of parameters before you start. More
explanations will be given at the relevant section in this document.
Read the text carefully and remember to check what the resulting files
look like often as mistakes are easy to miss and hard to track down It
is better the

The next code chunk will make sure your environment is properly setup your environment and ensure your Rstudio session has all the packages needed.

The most common cause for errors are wrong pathways so make sure that
all

## Setting up you environment

First, install and load your packages, set the WD and set the pathways to the
different folders

Then, create the folders to store input and output files

Remember to pick a project name too

```{r include=FALSE}

# list packages that will be needed
pacakges <- c("jsonlite","httr","zip", "imager", "magick", "tidyverse", "magrittr","reticulate")

# install those packages that you dont have yet
install.packages( 
  setdiff(pacakges,installed.packages()[,1] )
)

if("reticualte" %in% setdiff(pacakges,installed.packages()[,1] )){
  print("never used reticulate? you may have to install python or link your existing python interpreter to Rstudio ")
  print("Install python or Anaconda or zip the files manually")
  
}  


library(jsonlite)
library(magick)
library(imager)
library(tidyverse)
library(magrittr)
library(reticulate)

# folder where the script is 
wd <- dirname(rstudioapi::getSourceEditorContext()$path)

# make a variable with the full pathway to your WD
setwd(wd)
getwd() -> wd
print(wd)

# folders:
# this folder will contains the files that you will have to upload to Colab
paste0(wd,"/yolov5files") -> for_yolo_files
dir.create(for_yolo_files) # make the dir if you haven't 
# this is the folder where your Biigle report have to go
paste0(wd, "/reports") -> reports_folder
dir.create(reports_folder) # # make the dir if you haven't 
# this folder will be used later once you have made predictiosn with your CNN
paste0(wd, "/YoloResults") -> yolo_results
 dir.create(yolo_results) # # make the dir if you haven't 
# this folder will be used later when uploading annotations back to Biigle
paste0(wd, "/taxonomy") -> taxonomy_dir
dir.create(taxonomy_dir) # # make the dir if you haven't 


```

That is your environment set up. All your input data and results will be
there. Move your Biigle reports into the reports folder. They need to
the be the CSV reports of individual volumes. There can be more than
one. They also should be the zip format, No need to unzip them

## Import and filter the data from Yolo

Import the Biigle report (or aggregated reports). This take every report
loaded into the reports folder

```{r pressure, message=FALSE}
# list the csv tables - 
list.files(reports_folder, pattern = "csv_image_annotation_report") -> files

# 2) make a metadata table --------------------------------------------------------------------------------

tibble(file = files ) %>%
  mutate(table_name = str_remove(file,pattern = ".zip")) %>% 
  # make a column of volume ID number
  mutate(volume = str_remove(table_name,pattern = "_csv_image_annotation_report") ) -> annotationTables
 

# make a list to store all transformed tables tables
Dframes  <- as.list(1:nrow(annotationTables))

for (i in seq(Dframes)) {
  # select the table number i
  annotationTables %>% slice(i) -> meta.i
  # import it
  meta.i %>% pull(file ) %>% paste(reports_folder,.,sep = "/") %>%
    read_csv(col_types = cols()) -> D.i

  # add the metadata 
 bind_cols( D.i,meta.i) ->  Dframes[[i]]

}

# This is your table of everything 
Dframes %>% bind_rows() -> All_annotations


# show a list of labels
All_annotations %>% count(label_name) %>% arrange(desc(n)) %>%  print()

```

Now your Annotations are imported, select those you want to convert to
Yolo Format

you are probably using an OTU catalogue on Biigle So your label names
may not be the most explicit you can create a translation table and use
it here

This part needs to be manually checked to input the right names

```{r}

# add other names -- 
# make a list of labels you want to take to train your model on
tibble(label_name = All_annotations %>% distinct(label_name) %>%  pull) -> ALL_OBJ_NAME

# make a new column of better names (rather than the Biigle catalogues names)
ALL_OBJ_NAME %<>% mutate( Yolo_labelNames = label_name %>%  as.factor() )

# add a class code - a numerical code that will be used by yolo instead of the text labels
ALL_OBJ_NAME %<>%  mutate( class_code = 0:(nrow(ALL_OBJ_NAME) -1 ))

# add a column of abundance of each label in your dataset
All_annotations %>% count(label_name) %>%
  left_join(ALL_OBJ_NAME, by = "label_name") %>% arrange(class_code) -> ALL_OBJ_NAME

# view you final table
print(ALL_OBJ_NAME)


```

The table above shows the available classes, given names

By default, all annotations and labels present in your annotations
images will be retained for training. But, here you can apply filter to
choose which labels you want to keep. This code block lets you set those
options in one place so the rest of the code needs no input.

# !! Your Input is needed HERE !!

-   Pick a project name
-   filterimages: whether or not all the images you have annotations for should go into your Yolo training set. if not, add a specific filter in the appropriate code box further down. 
-   filterlabels: Choose the labels you wanto to teach yolo to detect
    and discard the other
-   ChangeYoloLabels: By default, Yolo will use the same lable names as
    Biigle. Enable this to give those labels a sensible name. You may be
    using a code that make little sense or a long name that takes up all
    the space above your bounding boxes.
-   resample_images: In case you have too many images for the Yolo
    training process, set a number of images that will randomly be taken
    out of the initial batch. By default, this is set to **1000**
    images. which is a relatively large amount of data to train a Yolo
    model on (with transfer learning at least) but feel free to
    experiment with that number if you have lot of data available and a
    powerful machine.
-   downloadimages: Yolo needs the images with the annotation to learn
    to detect objects. You don't always have the images on your computer
    ready but they should be on a server so Biigle can find them. Enable
    this to download them in your WD. **It will consume a lot of
    space!!**
-   You will have to supply the server address where your images are.
    This is the same URL as the one you gave to the Biigle volume (so
    you can find it there if you are unsure). **Important: If your
    images are in several online location, this will not work!!**
-   **Note** that if you have the images on your machine, you need to
    set the path the folder where they all are, even if they are in
    subfolders within that folder.
-   pcent_to_train: This is the proportion of your images that will go
    into training set (the set to calculate yolo performances on). 
    Default is 0.75

Print all the labels so you can see what species Yolo will learn to
detect

```{r}
# make a string of lables
ALL_OBJ_NAME %>% pull(label_name) %>%paste(collapse ="' , '") %>%  paste0("  '", ., "'  ")
```

Just take that string and manually edit it to filter the labels

**pro tip: if you want to merge two Biigle labels into one, give them
the same yolo_name labels**

# Set the options in this chunk:

```{r}

# Set the name of your colab project
projectName <- "ProjName"


# Do you want to filter your images? - - - - - - - - - - - - - - - - - - - 
filterimages <- "no" # "yes" / "anything else"
# if you enabled if, input the filter in the next chunk


# Do you want to filter your annotations? - - - - - - - - - - - - - - - - - - - 
filterlabels <- "no" # "yes" / "anything else"
# if so, make a variable with the OTUs you want to keeo
# example:
#labelsToKeep <- c("biigle_label1","biigle_label1","biigle_label1")


# do you want to change some of the labels to better names  - - - - - - - - - - 
ChangeYoloLabels <- "no" # "yes" / "anything else"
new_yolo_labels <- c()
# example:
# new_yolo_labels <- c("yolo_label1","yolo_label2","yolo_label3")

 
# how many images total are you taking? - - - - - - - - - - - - - - - - - - - - 
resample_images <- 1000



# do you want to download the images from your biigle volume? - - - - - - - - - 
downloadimages <- "no" # "yes" / "anything else"
# provide the URL to where the images are stored
    # either: 
    serverURL <- "https://[servername].com/[bucketname]/ProjName"

    # example: "https://serverserverserver.s3.eu-west-2.amaaws.com/cruisephotos"
    # note that this will not work if your images are on Biigle's server (url will not be valid for DL)
    # or, set path to local images:
    local_images_dir <- "C:/path/to/images/dir"
    # example:
    #      "C:/path/to/images/dir"
    
# set the proportion of images that will go into the training set - - - - - - 
    pcent_to_train <- 0.75 # 0.75 is 75% in training 25% for validaiton
    


```

If you have enabled the label filters, your table will be reduced to the
annotations with these labels

the final table of labels will come up as a prompt for you to review and change manually if you want to. The script will not move on until you close it

```{r}

All_annotations -> d_annotations

# make a list of labels
ALL_OBJ_NAME %>% select(-class_code) %>%
  mutate(class_code = 0:(nrow(.) - 1))  -> OBJ_NAME

# filtering images if you enabled it - - - - - - - - - - - - - - - - - - - - - -
if (filterlabels == "yes") {
  d_annotations <- d_annotations %>% group_by(filename) %>%
    # filter out all the images that have a Blurry label
    filter(!all(c("Blurry") %in% label_name))
}


# filter labels if you have enabled it - - - - - - - - - - - - - - - - - - - - - -
if (filterlabels == "yes") {
  print("filtering labels")
  # if further filtering is necessary:
  # extract the right annotations
  d_annotations  %>%
    # filter with OTU/label name
    filter(label_name %in%  labelsToKeep) %>%
    # exclude a volume (using its code)
    # filter( volume != 2164) %>%
    # take the images of a specific annotator (OR remove them)
    filter(lastname == "Meyer")  %>%
    ungroup() -> d_annotations
  
  # also filter the OBJ_NAME table
  ALL_OBJ_NAME %>% select(-class_code) %>%
    filter(label_name %in%  labelsToKeep) %>%
    mutate(class_code = 0:(nrow(.) - 1))  -> OBJ_NAME
  
  # update the number of labels
  OBJ_NAME %>% select(-n) %>% left_join(d_annotations %>%  count(label_name),
                                        by = join_by(label_name)) -> OBJ_NAME
  
}

# changes the Yolo names to something sensible - - - - - - - - - - - - - - - - - - - - - -
if (ChangeYoloLabels == "yes") {
  print("changing yolo labels")
  # If the catalogue names are no good labels put a new names column -- !! make sure they are in the right order
  if (length(new_yolo_labels) == 0) {
    OBJ_NAME %<>% mutate(Yolo_labelNames = paste0("Class" , class_code))
    # if you supplied new names, take these
  } else if (length(new_yolo_labels) == nrow(OBJ_NAME)) {
    OBJ_NAME %<>% mutate(Yolo_labelNames = new_yolo_labels)  %>% filter()
  } else{
    print("cannot replace labels")
  }
  # this is equivalent to this line if you have 3 classes
  
}

# now add these new names to the annotation
d_annotations %<>% left_join(OBJ_NAME, by = "label_name")


# shuffle the images in the table to randomize the order in which they are taken
d_annotations %>% distinct(filename) %>% pull() -> imgs

# if you have set an image resampling number below what you have available, it will randomly take your desired number of images
if (resample_images < length(imgs)) {
  print(paste0("resampling images to keep ", resample_images))
  d_annotations %>% filter(filename %in% (imgs %>%  sample(resample_images))) -> d_annotations
  
  # and reset the class counts
  OBJ_NAME %<>% select(-n)
  OBJ_NAME <- d_annotations  %>%
    count(label_name) %>%
    left_join(OBJ_NAME, by = "label_name") %>%
    arrange(class_code)
  
  
} else{
  print(paste0("taking all ", resample_images, " images "))
}


# you can manually edit it
OBJ_NAME %<>% edit() # this will open a window. Type your changes and close


# make a list of the names of your labels in Yolo
d_annotations %>%
  distinct(Yolo_labelNames) %>%  pull(Yolo_labelNames) %>%  as.character() -> OBJ_OTU
print(paste0("Model will be trained on: ", OBJ_OTU %>% paste(collapse = " , ")))

print(paste0(
  nrow(d_annotations),
  " Annotations in ",
  nrow(d_annotations %>% distinct(filename)),
  " images"
))


```

The last printed vector is the list of objects your model will learn to
detect.

# have a look at the final class count

Ideally you want as balanced a training set as possible and a validation
set with the same prevalence of each class. In practice, you will most
likely not have any of that but you should be aware of that bias in your
dataset

```{r}
d_annotations %>%  
  ggplot(aes(Yolo_labelNames, fill = Yolo_labelNames)) +
  geom_bar() + 
  theme_bw() +
  scale_fill_brewer(palette="Dark2", name = "Label names:") + 
  labs(y = "Number of unique annotations",
       x = "Labels names in YOLO files",
       title = "Number of annotations per label names",
       caption = "This is how much examples of each species your YOLO model will be trained on")
```

## Convert annotations format

Yolo uses a specific format which is different from the way Biigle
exports the coordinates of the manual annotations depending on the shape
of your annotations the conversion needs to be written differently

the coordinates have different origins and are expressed in pixels in
Biigle while yolo express them in relative height and width of the image

```{r message=FALSE}
 
d_annotations -> ForYoloimageAnnotation
# put the attributes of the annotations into the right format
d_annotations %>%
  split(.$annotation_id) %>%
  map(
    function(X)
      tibble(
        image_width = X$attributes %>%  fromJSON() %>%
          magrittr::extract("width") %>% as.numeric(),
        image_height = X$attributes %>%  fromJSON() %>%
          magrittr::extract("height") %>% as.numeric()
      )
  ) %>%
  bind_rows(.id = "annotation_id") %>%
  mutate(annotation_id = as.numeric(annotation_id)) %>%
  left_join(ForYoloimageAnnotation , by = "annotation_id") %>%
  rename(label = Yolo_labelNames) -> ForYoloimageAnnotation

# First explore the label name and
ForYoloimageAnnotation %>%  count(shape_name) %>%  print()
# this is what we are aiming for
yolopointnames <-
  c("center.x" , "center.y" , "width", "height")

# if the shape is rectangle -------------------------------------------------------------------------------
    
    ForYoloimageAnnotation %>% filter(shape_name == "Rectangle") -> d.i
    # this is the worst shape as each corner has to be considered seprately
    pointnames <-
      c("xleft1",
        "ybottom1",
        "xleft2",
        "ytop1",
        "xright1",
        "ytop2",
        "xright2",
        "ybottom2")
    
    d.i %>%
      pull(points) %>%
      str_remove(pattern = fixed("[")) %>%
      str_remove(pattern = "]") %>%
      str_split(pattern = ",")  -> l.i
    
    map(l.i, function(X)
      tibble(points = pointnames , value = unlist(X) %>%  as.numeric()) %>%
        # because manual rectangles
        pivot_wider(names_from = points, values_from =   value) %>%
        mutate(
          width = abs(max(c(xleft1, xleft2, xright1, xright2)) - min(c(xleft1, xleft2, xright1, xright2))),
          height = abs(max(c(ytop1, ytop2,ybottom1, ybottom2)) - min(c(ytop1, ytop2,ybottom1, ybottom2))),
          center.x = mean( c( max(c(xright1, xright2)), min(c(xleft1, xleft2)) )  ),
          center.y = mean(c( max(c(ytop1, ytop2)) , min(c(ybottom1, ybottom2))) ) ,
        ) %>%   select(all_of(yolopointnames))) -> yolo_d.i
    
    # shape the rectangle data
    yolo_d.i %>% bind_rows() %>%
      bind_cols(select(
        d.i,
        label,
        class_code,
        annotation_id,
        filename,
        image_width,
        image_height
      )) -> yolo_rectangle
    
# in case of circle --------------------------------------------------------------------------------

# taking the full radius of a circle takes up a lot of background with it
# for the xenos in the AUV, that is fine but hte the ROV xenos circle are tighter. 
# so the height should be the whole diameter of the circle (2 radius) 
# !!!!!!!!!!!!!!!!!!!!!!!!  --- THAT NEEDS TO BE ADJUSTED

radius_factor <- 2 # 2 means you take the whole diamter of the circle as width

# for a whole table
ForYoloimageAnnotation %>% filter(shape_name == "Circle")    ->  d.i
pointnames <- c("center.x", "center.y", "radius")

# list all the points coordinates
d.i %>%
  pull(points) %>%
  str_remove(pattern = fixed("[")) %>%
  str_remove(pattern = "]") %>%
  str_split(pattern = ",") -> l.i

map(l.i, function(X)
  tibble(points = pointnames , value = unlist(X) %>%  as.numeric()) %>%
    pivot_wider(names_from = points, values_from =   value) %>%
    mutate(
      width = radius_factor * radius,
      height = radius_factor * radius ,
      center.x = center.x,
      center.y =  center.y
    )  %>%
    select(all_of(yolopointnames)))   -> yolo_d.i


# put back into a table format and add the imagename
yolo_d.i %>% bind_rows() %>%
  bind_cols(select(
    d.i,
    label,
    class_code,
    annotation_id,
    filename,
    image_width,
    image_height
  )) -> yolo_circles

# in case of a point annotation -------------------------------------------------------------------------
    #   Avoid points if you can afford it
# what size is the square around the point going to be (in pixels)
pointsRadius <- 20


ForYoloimageAnnotation %>%  filter(shape_name == "Point")  ->  d.i
pointnames <- c("center.x", "center.y")

d.i %>%
  pull(points) %>%
  str_remove(pattern = fixed("[")) %>%
  str_remove(pattern = "]") %>%
  str_split(pattern = ",") -> l.i

map(l.i, function(X)
  tibble(points = pointnames , value = unlist(X) %>%  as.numeric()) %>%
    pivot_wider(names_from = points, values_from =   value) %>%
    mutate(
      width = radius_factor * pointsRadius,
      height = radius_factor * pointsRadius ,
      center.x = center.x,
      center.y =  center.y
    ) %>%
    select(all_of(yolopointnames)))  %>%
  bind_rows() %>%
  bind_cols(select(
    d.i,
    label,
    class_code,
    annotation_id,
    filename,
    image_width,
    image_height
  )) -> yolo_points

# in case of a polygon ------------------------------------------------------------------------------------------
ForYoloimageAnnotation %>%  filter(shape_name == "Polygon")  ->  d.i

d.i %>%
  pull(points) %>%
  str_remove(pattern = fixed("[")) %>%
  str_remove(pattern = "]") %>%
  str_split(pattern = ",") -> l.i

#l.i[[1]] -> X
map(l.i, function(X)
  tibble(
    points = rep(c("x", "y"), length(X) / 2),
    index = seq(1:(length(X) / 2)) %>% rep(each = 2) ,
    value = unlist(X) %>%  as.numeric()
  ) %>%
    mutate(value = ifelse(value < 0, 0, value)) %>%
    # get the maximums of Xs
    group_by(points) %>%  summarise(min = min(value), max = max(value)) %>%
    # calcualte centers
    rowwise() %>% mutate(cut = max - min, center = mean(c(min, max))) %>%
    
    pivot_longer(cols = c(min, max, center, cut)) %>%
    mutate(
      pointnames = c(
        "xleft",
        "xright",
        "center.x",
        "width",
        "ytop",
        "ybottom",
        "center.y",
        "height"
      )
    ) %>%
    select(pointnames, value) %>%
    pivot_wider(names_from = pointnames, values_from =   value) %>%
    select(all_of(yolopointnames))) %>%
  bind_rows() %>%
  bind_cols(select(
    d.i,
    label,
    class_code,
    annotation_id,
    filename,
    image_width,
    image_height
  )) -> yolo_polygons
# get the minimum
 

# if it is an Ellipse ---------------------------------------------------------------------------------

# Please do not use Ellipses

#  Apply rescaling ======================================================================================

# now you have a table of annotations in Yolo format
rm(yolo_d.i)
bind_rows(yolo_rectangle, yolo_points, yolo_circles, yolo_polygons) %>%  arrange(annotation_id) -> yolo_d.i

# now normalize for each image - transform coordinates in pixels into relative heights and width

yolo_d.i %>%  mutate(
  center.x = center.x / image_width,
  center.y = center.y / image_height,
  width = width / image_width,
  height = height / image_height
) -> yolo_annotations

```

## Add the pathway to the images

If you decided to download the images from Biigle, you have already
provided the URL link to the server where the images are stored
(right??). This code block will creat a folder (imageDL) in your WD and
proceed with downloading them after checking they are not already in the
imageDL folder.

you will find the server URL in the settings of the Biigle volume if you
are using multiple volumes, repeat this step for each one. If you have
too many, you should be doing this outside of this script anyway

```{r  message=FALSE}

if(downloadimages == "yes") {
  # if you supplied a url to get the images from
  print(paste0("Images will be found at:",serverURL) )
  # enter server URL
  paste0(wd, "/imageDL") -> imageDLdir
  dir.create(imageDLdir)
  
  #
  d_annotations %>% distinct(filename) %>% pull -> imgs_list
  
  for (imageName in imgs_list) {
    print(imageName)
    # dont download the image if it is already there
    if (!file.exists(paste0(imageDLdir, "/", imageName))) {
      print(" -- Downloading -- ")
      paste0(serverURL, "/", imageName) %>% download.file(destfile = paste0(imageDLdir, "/", imageName),
                                                          mode = 'wb')
    } else{
      print("already downloaded")
    }# checking image doesnt exist before downloading
    
  }# download images to your yolo directory
  
  # delete the image list vector
  rm(imgs_list)
  
  # set the DL folder to the location of your images
  images_dir <- imageDLdir
  
# you  
}else if(local_images_dir != "C:/path/to/images/dir" &
         downloadimages != "yes"){# if you supplied a path to a folder where your images are
  
  images_dir <- local_images_dir
  print(paste0("Images will be found in: ",images_dir) )
  
# if you haven't   
}else{
  print("You have not supplied images. You cannot train a CNN without images")
}




```

Before images can be moved to a specific folder along with the
annotations, R needs to know where they are so a table of the images
pathways is needed.

This code looks into the folder that contains the images and make a
table of images and their respective pathways

```{r}

# make a table of images and path to each of them
images_dir %>%  list.files(recursive = T, full.names = T) -> imgs_paths
images_dir %>%  list.files(recursive = T,
                           full.names = F,
                           include.dirs = F) -> imgs_list
imgs_list %>%  str_split(pattern = "/") %>%
  map( ~ extract2(.x, length(.x))) %>%
  unlist() -> imgs_names

# format the table
tibble(image = imgs_list,
       path = imgs_paths,
       filename = imgs_names) -> img_PATHWAYS

# add the pathways to the images - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
# merge it with the the images metadata including the path and dimensions
img_PATHWAYS %>%  left_join(yolo_annotations, . , by = "filename") -> yolo_annotations_path

# make sure all images are matched to their pathways
yolo_annotations_path %>% filter(is.na(path)) -> mismatched #

if (nrow(mismatched) == 0) {
  print("All images have been found - proceed")
} else{
  paste0(
    nrow(mismatched %>% distinct(filename)),
    " images have not been matched (out of ",
    nrow(yolo_annotations %>% distinct(filename)),
    ")"
  )
  paste0("mismatched images are: ",
         mismatched %>%  distinct(filename) %>% pull)
  
}

# if you want to know what the mismatches are, call the mismatched table in the console


```

if it says 0, then you are clear to proceed. If not, try to see why some
images were not found in the directory. Often there might be a
discrepancy in the names, the date can be written wrong or the the format
is different (jpg on Biigle but png on you machine)

## For safety, you may want to to look at what your resized annotations look like:

!! check the amount you are resampling. If you have a small number of
images, taking a smaller subset may not be necessary

```{r}


# randomly take a couple of images to see how the annotations plot over these
imgforplot <- yolo_annotations_path %>%
  distinct(filename) %>%
  pull(filename) %>%
  sample(20)  # !!! SET THE NUMBER OF IMAGES TO PLOT HERE !! 
yolo_annotations_path %>% filter(filename %in% imgforplot) -> yolo_annotationsForplot

yolo_annotationsForplot %>%   distinct(filename) %>%  pull() -> imgs


# make a folder of images where your images with annotations will be
target_dir <- paste0(wd, "/testAnnotations")

target_dir %>% dir.create()

for (I in seq(imgs)) {
  imgs[I] -> img.I
  print(img.I)
  
  # open the annotations 
  yolo_annotationsForplot %>% filter(filename == img.I) -> annotations.I
  
  paste0(nrow(annotations.I)," annotations") %>% print()
  
  # open the images
  annotations.I %>%  distinct(path) %>%  pull() %>% magrittr::extract(1) %>% 
  load.image( ) -> image2
  
  
  for (i in 1:nrow(annotations.I)) {
    # take the annotation
    
    annotations.I %>%  slice(i) -> r.i
    
    # descale teh coordinates to pixels
    xleft <-
      (r.i$center.x * width(image2)) - (r.i$width * width(image2) / 2)
    ybottom <-
      (r.i$center.y * height(image2)) - (r.i$height * height(image2) / 2)
    xright <-
      (r.i$center.x * width(image2)) + (r.i$width * width(image2) / 2)
    ytop <-
      (r.i$center.y * height(image2)) + (r.i$height * height(image2) / 2)
    
    c(xleft  , ybottom  , xright   , ytop) -> v
    
    # plot it over the image
    imager::draw_rect(
      image2 ,
      v[1],
      v[2],
      v[3],
      v[4],
      opacity = 0.25 , # adjust here to make rectangle more transparent (0) or less (1)
      filled =  TRUE,
      color = rainbow(nrow(annotations.I))[i]
    ) -> image2
    
    
     
  }
  
  # export the image
  
  imager::save.image(image2, paste0(target_dir,"/",img.I %>%  str_replace(pattern = "png",replacement = "jpg") )  )
  
}

```

## Make training and testing set

Now you will separate the annotations between a training and validation
folders.

note that with Yolo, you need a validation set that is used throughout
training to calculate mAP at regular intervals. This may be refereed to
as train and val

This step will vary depending on how you choose to resample you data.
You may not want to take all your images

Both training and testing sets will be saved as tables that can be re-open later

the list of labels will also be saved as a txt file as it is sometime necessary for other annotation and ML applications

```{r  message=FALSE}

# shuffle the images in the table to randomize the order in which they are taken
yolo_annotations_path %>% distinct(filename) %>% pull() -> v

sample(v, length(v)) %>%
  tibble(filename = ., shuffleid = 1:length(.)) %>%
  left_join(yolo_annotations_path) -> d1

# take a set amount of the images for the training set
  d1  %>%
    distinct(filename) %>%
    pull(filename) %>%
    sample(length(.) * pcent_to_train)  -> v1


# once you have your set of images, take the corresponding annotations -- change v1 to v1small if you want less images 
d1 %>% filter(filename %in% v1) -> d_training
# Keep a set that will be used to test the CNN performances and calculate recall and precision
d1 %>% filter(!filename %in% v1) -> d_testing_Val # this will take annotations that were not used for training as validation set

# print down how many annotations you have in training
print(paste0(nrow(d_training), " annotations in training (", d_training %>% distinct(filename) %>% nrow()," images)"))
# and print down how many files you should have in your folder
print(paste0(d_training %>%  count(filename)  %>% nrow() * 2, " single files in training folder"))
d_training %>%  write_csv(paste0(for_yolo_files, "/train_set.csv"))

# print down how many annotations you have in testing
print(paste0(nrow(d_testing_Val), " annotations for testing (", d_testing_Val %>% distinct(filename) %>% nrow()," images)"))
# and print down how many files you should have in your folder
print(paste0(d_testing_Val %>%  count(filename)  %>% nrow() * 2, " single files in testing folder"))
d_testing_Val %>%  write_csv(paste0(for_yolo_files, "/test_set.csv"))

# export the labels
# export the labels
OBJ_NAME %>% arrange(class_code) %>% write_csv(paste0(for_yolo_files, "/",projectName,"_labels_info.csv"))
OBJ_NAME %>% arrange(class_code) %>%  select( Yolo_labelNames) %>% write_delim(col_names = FALSE, paste0(for_yolo_files, "/",projectName,"_labels.txt"))

```

**You can manually update the csv files in Excel, they will be re-open in the next code chunk**

## Make the files for Yolo local and on Colab

# Note that this reads the csv tables exported earlier. You can modify those
manually and, then, convert them to YOLO format 

The annotations have to be written into a txt file for each image.
images and annotations have to be together in a folder

If you so desire you can rescale your images to save space on cloud (if you train on the cloud) storage. This is not recommended as it may impact the performances of your CNN 

```{r  message=FALSE}
 


# make yolo zip files for training and testing sets
for (training_OR_testing in c("train", "test")) {
  if (training_OR_testing == "train") {
    # teh trainin gset
    read_csv(paste0(for_yolo_files, "/train_set.csv")) ->  annotations
    labelsfolder  <-
      paste0(for_yolo_files, "/", projectName, "/labels/train")
    imagefolder <-
      paste0(for_yolo_files, "/", projectName, "/images/train")
    print("Making the training set")
  } else if (training_OR_testing == "test") {
    read_csv(paste0(for_yolo_files, "/test_set.csv")) -> annotations
    labelsfolder  <-
      paste0(for_yolo_files, "/", projectName, "/labels/val")
    imagefolder <-
      paste0(for_yolo_files, "/", projectName, "/images/val")
    print("Making the testing set")
  }
  
  # create a fodler
  
  dir.create(labelsfolder, recursive = T)
  dir.create(imagefolder, recursive = T)
  
  
  # for each image in the annotations table
  annotations %>% count(filename) %>%  pull(filename) ->  imgs
  for (i in seq(imgs)) {
    imgs[i] -> imgs.i
    # get the image name no matter the extention
    imgs.i %>%  str_split(pattern = fixed(".")) %>% unlist()  %>%   magrittr::extract(1)  -> imagename.i
    
    # set path the image
    # or from the existing repository
    # remove what is after the "." (will break if not )
    # imgs.i %>%  str_split(pattern = fixed(".") ) %>% unlist()  %>% magrittr::extract(1)  -> imagename.i
    # remove the last 4 characters
    imgs.i %>%  str_sub(end = -5)  -> imagename.i
    
    # set path the image
    # or from the existing repository
    imagepath.i <-
      annotations %>%  filter(filename == imgs.i) %>%  distinct(path) %>% pull()
    
    
    # some time stamps can be matched multiple times if they are records for several species
    # pick the first one
    if (length(imagepath.i) > 1) {
      imagepath.i[1] -> imagepath.i
    }
    
    annotations %>%  filter(filename == imgs.i) %>%
      distinct(center.x, center.y,  width, height, .keep_all = T) %>%
      select(all_of(c("class_code", yolopointnames))) -> labels_txt
    # round the coordinates to only 2 digits
    labels_txt %<>%
      mutate(across(c(center.x, center.y, width, height), ~  round(.x, digits = 2)))
    
    # Export the txt file
    write.table(
      labels_txt,
      quote = FALSE,
      row.names = FALSE,
      col.names = F,
      file = paste0(labelsfolder, "/", imagename.i, ".txt")
    )
    
    # and move the image
    file.copy(
      from = imagepath.i,
      to = paste0(imagefolder, "/", imagename.i, ".jpg"),
      overwrite = T
    )
    
    
    rm(labels_txt, imagepath.i, imagename.i)
    
  } # next image
  
  
}# next set




```

One more file is necessary: a .yaml file that has the info on the
structure of your dataset. the path arguments tells yolov5 where to look
for images and annotations. The exact path will depend on where your
stored your things and how you want to run it. by default I have set it
in the parent directory (../) of the YoloV5 on your local or virtual
machine. But you may have to edit it if you want to put it in the 'data'
dir in the yolov5 repo folder, just put: './data/projectName' pathways
to images and labels depend on that root path

number of classes and class names should be gathered from your tables
This is simple: just a list of names of your category. If you have only
one, it should just be: Acanella

if you have more than one, this file should be:

class1 class2 class3 class4

You can do this step manually if you prefer. It is a bit simple that
way, particularly if you have many classes

```{r}
# make the yaml file

data.frame(
  X = c(
    paste0("path: ./datasets/", projectName, " # dataset root dir"),
    "train: images/train # train images (relative to 'path')" ,
    "val: images/val # val images (relative to 'path')" ,
    "test:  # test images (optional)",
    "#Classes",
    paste0("nc: ",length(OBJ_OTU),"  # number of classes"),
    paste0("names: ", paste0(OBJ_OTU,collapse = "','") %>% paste0("['" ,. , "'] # classes names") )
  )
) %>%
  format_csv(col_names = F) %>%
  # remove the last line jump so the file does not end with an empty line
  str_sub(start = 0, end = -2) %>% 
  # remove some " that shouldnt be there
  str_replace(pattern = '"names',replacement = "names") %>% 
  str_replace(pattern = 'names"',replacement = "names") %>%
  cat(sep = "",
      file = paste0(for_yolo_files,"/",projectName, "/", "dataset.yaml"))


```

So Now you have you Data ready. You can stop here if you want to train
locally

# Zip for faster upload to colab

zip the folders you just made 

This is not a necessity but makes life easier especially for larger
datasets that you are going to work with on a regular basis

use python to zip the files (the R zipping is buggy when used in
markdown... annoyingly)

**Reminder: this will not work if you have not configured python to work
in Rstudio** 
Or it will prompt you to install it

```{python}
import os
import shutil

# calling r objects into the python session can be done with r.[objectname]
wdp =  r.getwd() # this only works of your RMD is in your WD
wdp =  r.wd
wdp = wdp.replace('/','\\')
# for the training set
path = os.path.join(wdp,"yolov5files" )
dir_name =  os.path.join(path,r.projectName )
# make a zip
shutil.make_archive(os.path.join(path,r.projectName ) , 'zip',dir_name)

```

now go to yolo
